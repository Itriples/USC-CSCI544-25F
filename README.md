USC-CSCI544-25F

# 1. LLMs for Time Series Forecasting
## Idea
Use **LLMs** to improve **time series forecasting (TSF)** tasks.

## Related Papers
- [Time-LLM: Time Series Forecasting by Reprogramming Large Language Models](https://arxiv.org/abs/2310.01728)
- [CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning](https://arxiv.org/abs/2403.07300)

## Datasets
- **ETT** (Electricity Transformer Temperature)
- **Electricity**
- **Traffic** <br>
See datasets [here](https://drive.google.com/drive/folders/1ZOYpTUa82_jCcxIdTmyr0LXQfvaM9vIy)



# 2. Multi-Agent Market Researcher (Applied)
- Agents: one scrapes competitor data, one summarizes market trends, one generates SWOT analysis, one validates findings.
- Use case: Automates consulting-style market research for startups or SMEs.

# 3. 	Recommendation System with Text + Metadata (Applied)
- Combine embeddings from text (e.g., product reviews) with structured data (ratings, price) for hybrid recommendations.
- Great e-commerce angle.

# 4.  Faithful & Source-Grounded Summarization (Research)
- Build a summarization model that not only generates concise summaries but also highlights supporting evidence spans in the source documents.
- Novelty: Tackles the hallucination problem in LLM summarization.
- Reference:
  - Maynez, J., et al. (2020). On Faithfulness and Factuality in Abstractive Summarization. ACL. ğŸ“„
	- Ladhak, F., et al. (2022). Faithful Summarization with Attribution. ACL. ğŸ“„

# 5. Explainable Toxicity Detection (Research)
- Train a toxicity classifier that not only predicts labels but also provides human-interpretable explanations (e.g., highlighting offensive spans).
- Novelty: Bridges fairness + explainability in NLP.
- Reference:
  - Sap, M., et al. (2019). The Risk of Racial Bias in Hate Speech Detection. ACL. ğŸ“„
	- Mathew, B., et al. (2021). Hatexplain: A Benchmark Dataset for Explainable Hate Speech Detection. AAAI



# Multi agent research
Title:
Hierarchical Multi-Agent QA with Specialized Roles and a Verifier for Attribution Reliability

1. Motivation

Large Language Models (LLMs) often hallucinate or provide unsupported claims in complex QA tasks. While multi-agent systems have shown promise, they still lack attribution reliability â€” the ability to ground every answer in verifiable evidence. Recent industry systems (e.g., Anthropicâ€™s Research Assistant with a Citation Agent) highlight this gap, but systematic academic evaluation is missing.

Our project aims to investigate whether combining (a) role specialization (Searcher, Analyst, Writer) and (b) an independent Verifier/Citation Agent under a centralized Orchestrator can significantly improve accuracyâ€“attributionâ€“cost trade-offs in QA tasks.

2. Literature Review

Anthropic (2025). How we built a multi-agent research system.
[Anthropic Blog] â€“ æè¿° Lead Researcher + Citation Agent æ¶æ„ï¼Œå¼ºè°ƒè¯æ®æº¯æºå’Œå®½åº¦ä¼˜å…ˆç ”ç©¶æŸ¥è¯¢ã€‚

Jin et al. (2025). Talk Hierarchically, Act Structurally: Structured Communication Protocols for Multi-Agent LLM Systems. arXiv:2502.11098.
æå‡º structured communication + hierarchical refinementï¼Œæœ‰æ•ˆå‡å°‘åä½œå¹»è§‰ã€‚

Zhang et al. (2025). MACT: Multi-agent Cooperative Tuning for Complex Reasoning with LLMs. NAACL 2025.
ç”¨å¤šä»£ç†åä½œå¤„ç†è¡¨æ ¼é—®ç­”ï¼Œè¯æ˜ plannerâ€“executorâ€“tool ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚

Li et al. (2023). CAMEL: Communicative Agents for â€œMindâ€ Exploration. ICLR 2023.
ç»å…¸å·¥ä½œï¼Œæå‡ºå¤šä»£ç†è§’è‰²æ‰®æ¼”æ¡†æ¶ã€‚

Wu et al. (2023). AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation. Microsoft Research.
å¤šä»£ç†æ¡†æ¶ï¼Œå¹¿æ³›ç”¨äº orchestratorâ€“worker å®ç°ã€‚

Sun et al. (2024). MegaAgent: Scaling LLM-based Multi-Agent Collaboration without Predefined SOPs. arXiv:2408.09955.
æ¢ç´¢ä¸Šç™¾ä»£ç†çš„è‡ªæ²»ä¸åŠ¨æ€ç”Ÿ/æ€ agent ç®¡ç†ã€‚

Zhou et al. (2024). CollabEval: Enhancing LLM-as-a-Judge via Multi-Agent Collaboration. Amazon Science.
æå‡ºä¸‰é˜¶æ®µè¯„ä¼° (åˆè¯„â€“è®¨è®ºâ€“å®šå¤º)ï¼Œæå‡ä¸€è‡´æ€§å’Œé²æ£’æ€§ã€‚

Rashkin et al. (2021). ASQA: Factually Consistent Long-Form Question Answering. NAACL 2021.
æå‡º Attribution-based QA æ•°æ®é›†ï¼Œé€‚åˆè¯„æµ‹ citation precision/recallã€‚

Kamalloo et al. (2023). Evaluating Attributed QA: Can LLMs Reason with Cited Evidence? arXiv:2310.12848.
ç³»ç»Ÿæå‡º Attribution QA æŒ‡æ ‡ï¼ˆCitation F1ã€Attribution Recallï¼‰ã€‚

Manakul et al. (2023). SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. ACL 2023.
ç”¨å¼‚è´¨é‡‡æ ·æ£€æµ‹ LLM å¹»è§‰ï¼Œå¯ä½œä¸º Verifier è¯„ä»·å‚è€ƒã€‚

Chen et al. (2023). QAFactEval: Improved QA-based Factual Consistency Evaluation for Summarization. EMNLP 2023.
ç”¨äºå¥å­-è¯æ®è•´å«åº¦æ£€éªŒï¼Œå¸¸ç”¨äº QA/æ€»ç»“éªŒè¯ã€‚

Gupta et al. (2022). FEVER: A Large-scale Dataset for Fact Extraction and Verification. NAACL 2022.
äº‹å®æ ¸æŸ¥æ•°æ®é›†ï¼Œæ ‡æ³¨æ”¯æŒ/åé©³/æ— æ³•åˆ¤æ–­ä¸è¯æ®å¥ã€‚

Yang et al. (2018). HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. EMNLP 2018.
å¤šè·³é—®ç­”æ•°æ®é›†ï¼Œå« supporting factsï¼Œå¯ç”¨äº attribution è¯„æµ‹ã€‚

3. Proposed Method

Architecture:

Orchestrator: decomposes task, assigns roles.

Sub-agents:

Searcher retrieves evidence,

Analyst links evidence to sub-questions,

Writer synthesizes final answer with inline citations.

Verifier/Citation Agent: checks if every statement is properly supported (using AIS/QAFactEval), rejects unsupported outputs â†’ triggers rework.

Structured Protocol: every intermediate/final answer must include evidence slots (document ID + passage).

4. Experiments

Datasets:

HotpotQA (multi-hop QA with supporting facts)

FEVER (fact verification with labeled evidence)

(Optional) ASQA / ELI5-subset (long-form QA with attribution labels)

Metrics:

Accuracy: EM/F1 (HotpotQA), Label Accuracy (FEVER)

Attribution: AIS, Citation Precision/Recall/F1

Cost: tokens, #rounds, latency

Baselines:

Single-agent RAG/ReAct

Multi-agent (no specialization)

Multi-agent (specialization, no verifier)

5. Plan (Milestones)

Week 1â€“2: Literature survey + single-agent baseline (RAG/ReAct).

Week 3â€“4: Implement Orchestrator + specialized Sub-agents; run HotpotQA baseline.

Week 5â€“6: Add Verifier/Citation Agent + structured protocol; full evaluation on HotpotQA + FEVER.

Week 7â€“8: Ablation (remove verifier, remove specialization, remove evidence slots); analyze attributionâ€“accuracyâ€“cost trade-off; finalize report.

6. Expected Contributions

Empirical evidence that Verifier + specialization improves attribution reliability.

Quantitative analysis of accuracyâ€“attributionâ€“cost trade-offs.

Ablation showing which components contribute most (roles, evidence slots, verifier).

7. Datasets

Potential Usecase 1: FEVER (Thorne et al., 2018; Gupta et al., 2022 revision)
- Task: Fact verification â€” given a claim, classify as SUPPORTED, REFUTED, or NOT ENOUGH INFO using Wikipedia evidence.
- Why relevant: Directly evaluates attribution reliability since evidence must justify label.
- Agentic Example:
  - Claim: â€œThe Eiffel Tower is taller than the Empire State Building.â€
  - Workflow:
	1.	Searcher retrieves Wikipedia entries for Eiffel Tower and Empire State Building.
	2.	Analyst extracts relevant heights (324m vs 381m).
	3.	Writer produces: â€œThe claim is REFUTED: Eiffel Tower (324m) < Empire State Building (381m) [Wiki:Eiffel Tower; Wiki:Empire State Building].â€
	4.	Verifier confirms that numeric comparison is present in retrieved evidence.

Public Datasources to Use
- Wikipedia dumps (for HotpotQA/FEVER, readily available via Hugging Face Datasets or ElasticSearch-backed retrieval).
- HotpotQA supporting facts (via Hugging Face Datasets: hotpot_qa).
- FEVER dataset (via Hugging Face Datasets: fever).


**Potential Usecase 2: ASQA (Attribution QA) (Rashkin et al., 2021)**
- Task: Long-form QA with attribution labels â€” requires generating comprehensive answers with fine-grained citations.
- Why relevant: Tests if the multi-agent system can maintain coverage + reliability at scale in long-form outputs.
- Agentic Example:
  - Question: â€œExplain the contributions of Ada Lovelace to computing.â€
  - Workflow:
	1.	Orchestrator splits into facets: early life, collaboration with Babbage, significance of notes on Analytical Engine.
	2.	Searcher retrieves multiple relevant passages.
	3.	Analyst links evidence to each sub-facet.
	4.	Writer synthesizes multi-paragraph answer with inline citations after each claim.
	5.	Verifier ensures every factual statement (e.g., â€œfirst computer programmer,â€ â€œnotes on Analytical Engineâ€) is attributed.

Public Datasources to Use:
- ASQA dataset (via Hugging Face Datasets: asqa).
- Optional: QAFactEval synthetic pairs (Chen et al., 2023) to test verifier robustness.

 
**Potential Usecase 3: Multi-Agent Market Research**

1. Competitor Data (Scraper Agent)
	â€¢	Crunchbase Open Data Map (https://data.crunchbase.com/)
	â€¢	Company funding, investors, industry tags.
	â€¢	CB Insights (limited public reports) (https://www.cbinsights.com/research/)
	â€¢	Industry trend snapshots.
	â€¢	Alternative: Kaggle Startup Datasets (e.g., startups, companies, startup-investments) â€” cleaned competitor/funding info.
	â€¢	SEC EDGAR Filings (https://www.sec.gov/edgar.shtml)
	â€¢	Public company financials & competitor positioning.

2. Market Trend Summarization (Analyst Agent)
	â€¢	World Bank Data (https://data.worldbank.org/)
	â€¢	Macroeconomic and sectoral data.
	â€¢	OECD Data Explorer (https://data-explorer.oecd.org/)
	â€¢	Industry performance & policy trends.
	â€¢	Statista Public Reports (free subsets) (https://www.statista.com/)
	â€¢	Consumer adoption, market penetration (limited free tier).
	â€¢	Google Trends API (pytrends)
	â€¢	Consumer interest signals, seasonal product demand.

3. SWOT Analysis Generation (Writer Agent)
	â€¢	Builds on above sources but benefits from:
	â€¢	Kaggle â€œBusiness/Industry Reportsâ€ Datasets
	â€¢	E.g., retail, fintech, SaaS growth trends.
	â€¢	IBISWorld Summaries (free previews)
	â€¢	Sector strengths/weaknesses at macro level.
	â€¢	PitchBook public blog insights
	â€¢	Emerging market opportunities.

4. Validation (Verifier Agent)
	â€¢	News & Fact-Checking Sources:
	â€¢	GDELT Project (https://www.gdeltproject.org/) â€” global news events, entity mentions.
	â€¢	NewsAPI (https://newsapi.org/) â€” business/financial news feeds.
	â€¢	Kaggle: Fake News / Fact-checking Datasets (for testing citation verification).
	â€¢	Benchmark Datasets for Factual QA:
	â€¢	FEVER (claim verification).
	â€¢	QAFactEval (evidence-supported factuality checking).

**Example Workflow with Public Data**

Use Case: A startup in EV charging infrastructure wants competitor + trend insights.
1.	Scraper Agent â†’ pulls competitor data from Crunchbase API (funding rounds of EV charging companies).
2.	Analyst Agent â†’ summarizes growth signals using World Bank EV adoption stats + Google Trends (â€œEV charging station near meâ€).
3.	Writer Agent â†’ generates SWOT (Strength: rising demand; Weakness: capital-intensive infra; Opportunity: policy subsidies; Threat: Tesla Supercharger dominance).
4.	Verifier Agent â†’ cross-checks claims against news feeds (GDELT/NewsAPI) and funding numbers from Crunchbase.
